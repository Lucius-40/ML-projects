{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79b4a42b",
   "metadata": {},
   "source": [
    "Here, we will try to predict prices, data has been explored already "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b02ec92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.stats import yeojohnson\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.stats import shapiro\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    ExtraTreesRegressor,\n",
    "    BaggingRegressor,\n",
    "    AdaBoostRegressor\n",
    ")\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0681d185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1273, 12)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('laptopData.csv')\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9071d2",
   "metadata": {},
   "source": [
    "Column Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b896481",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols):\n",
    "        self.columns = cols\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    def transform(self, X, y=None):\n",
    "        X = X[self.columns]\n",
    "        return X \n",
    "    def fit_transform(self, X, y = None):\n",
    "        return self.transform(X)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954ad4d4",
   "metadata": {},
   "source": [
    "Fixing data type :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "273077d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTypeFixer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols =None):\n",
    "        self.cols = cols \n",
    "    def fit(self, X , y=None):\n",
    "        return self \n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        for col in self.cols:\n",
    "            if col == \"Inches\":\n",
    "                X_copy['Inches']= pd.to_numeric(X_copy['Inches'], errors='coerce').astype('float32')\n",
    "                X_copy['Inches']=X_copy['Inches'].fillna(X_copy['Inches'].mean())\n",
    "                X_copy['Inches']=X_copy['Inches'].apply(lambda x : float(x/2.54) if x > 17.5 else x)\n",
    "            elif col == \"Ram\" :\n",
    "                X_copy['Ram']= pd.to_numeric(X_copy['Ram'].str.replace('GB','').str.strip(), errors='coerce')\n",
    "                X_copy['Ram']= X_copy['Ram'].fillna(X_copy['Ram'].mean()).astype('int32')\n",
    "            elif col == \"Weight\":\n",
    "                X_copy['Weight']= pd.to_numeric(X_copy['Weight'].str.replace('kg','').str.strip(),errors='coerce').astype('float32')\n",
    "                X_copy['Weight'].fillna(X_copy['Weight'].mean(), inplace=True)\n",
    "        return X_copy\n",
    "    def fit_transform(self, X, y = None):\n",
    "        return self.transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c712ea6",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "989529ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtract(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols =None):\n",
    "        self.cols = cols \n",
    "    def fit(self, X , y=None):\n",
    "        return self \n",
    "    \n",
    "    def extract_memory_feat(self, df):\n",
    "        import re\n",
    "        import numpy as np\n",
    "        # Helper function to extract storage sizes\n",
    "        def parse_storage(mem_str):\n",
    "            ssd = hdd = flash = 0\n",
    "            if not isinstance(mem_str, str):\n",
    "                return ssd, hdd, flash\n",
    "            # Replace TB with 1000GB for easier parsing\n",
    "            mem_str = mem_str.replace('TB', '000GB')\n",
    "            # Find all (size, type) pairs\n",
    "            matches = re.findall(r'(\\d+)GB\\s*(SSD|HDD|Flash|Flash Storage)', mem_str)\n",
    "            for size, stype in matches:\n",
    "                size = int(size)\n",
    "                if 'SSD' in stype:\n",
    "                    ssd += size\n",
    "                elif 'HDD' in stype:\n",
    "                    hdd += size\n",
    "                elif 'Flash' in stype:\n",
    "                    flash += size\n",
    "            return ssd, hdd, flash\n",
    "        \n",
    "        df['SSD'], df['HDD'], df['Flash'] = zip(*df['Memory'].map(parse_storage))\n",
    "        return df\n",
    "    \n",
    "    # ...existing code for other extractors...\n",
    "    def fetch_processor(self, text):\n",
    "        if text in ['Intel Core i7', 'Intel Core i5', 'Intel Core i3']:\n",
    "            return text\n",
    "        elif isinstance(text, str) and text.split()[0] == 'Intel':\n",
    "            return 'Other Intel Processor'\n",
    "        else:\n",
    "            return 'AMD Processor'\n",
    "    \n",
    "    def extract_cpu_feat(self, df):\n",
    "        cpu_speed_pattern = r'\\b\\d+(?:\\.\\d+)?(?:GHz|Hz)\\b'\n",
    "        df['CPU speed']= pd.to_numeric(df['Cpu'].str.findall(cpu_speed_pattern).str.get(0).str.split('G').str.get(0), errors='coerce')\n",
    "        # Ensure column is string type before applying split\n",
    "        df['Cpu'] = df['Cpu'].astype(str)\n",
    "        df['Cpu Name'] = df['Cpu'].apply(lambda x: \" \".join(x.split()[0:3]) if isinstance(x, str) else \"Unknown\")\n",
    "        df['CPU type'] = df['Cpu Name'].apply(self.fetch_processor)\n",
    "        df.drop(columns=[ 'Cpu Name'], inplace= True)\n",
    "        return df \n",
    "\n",
    "    def extract_resolution_feat(self,df):\n",
    "        pattern = r'(\\d{3,4}x\\d{2,4})'\n",
    "        res = df['ScreenResolution'].str.extract(pattern)\n",
    "        res_splt = res[0].str.split('x', n=1, expand=True)\n",
    "        res_splt.columns = [\"X res\", \"Y res\"]\n",
    "        df[\"X res\"]= pd.to_numeric(res_splt['X res'], errors='coerce')\n",
    "        df[\"X res\"]= df[\"X res\"].fillna(df[\"X res\"].mean()).astype('int32')\n",
    "        df[\"Y res\"]= pd.to_numeric(res_splt['Y res'], errors='coerce')\n",
    "        df[\"Y res\"]= df[\"Y res\"].fillna(df[\"Y res\"].mean()).astype('int32')\n",
    "        df['IPS']= df['ScreenResolution'].apply(lambda x : 1 if 'IPS' in x else 0)\n",
    "        df['Touchscreen']= df['ScreenResolution'].apply(lambda x : 1 if 'Touchscreen' in x else 0)\n",
    "        df['PPI']= (np.sqrt((df['X res']**2)+(df['Y res']**2))/df['Inches'])\n",
    "        df.drop(columns=['X res', 'Y res'], inplace=True)\n",
    "        return df \n",
    "\n",
    "    def fetch_OS(self , text):\n",
    "        if text in ['macOS', 'Mac OS X']:\n",
    "            return \"Mac\"\n",
    "        elif 'Windows' in text :\n",
    "            return 'Windows'\n",
    "        else :\n",
    "            return \"Others\"\n",
    "     \n",
    "    def extract_OS(self, df):\n",
    "        df[\"Operating System\"]= df['OpSys'].apply(self.fetch_OS)\n",
    "        return df \n",
    "    \n",
    "    def extract_gpu(self , df):\n",
    "        df['Gpu'] = df['Gpu'].apply(lambda x: x.split()[0] if isinstance(x, str) else \"Unknown\")\n",
    "        return df\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        for col in self.cols :\n",
    "            if col == \"Gpu\":\n",
    "                X_copy = self.extract_gpu(X_copy)\n",
    "            elif col == \"Memory\":\n",
    "                X_copy = self.extract_memory_feat(X_copy)\n",
    "            elif col == \"OpSys\":\n",
    "                X_copy = self.extract_OS(X_copy)\n",
    "            elif col == \"ScreenResolution\":\n",
    "                X_copy = self.extract_resolution_feat(X_copy)\n",
    "            elif col == \"Cpu\":\n",
    "                X_copy = self.extract_cpu_feat(X_copy)\n",
    "        return X_copy\n",
    "\n",
    "    def fit_transform(self, X, y = None):\n",
    "        return self.transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260ae3b3",
   "metadata": {},
   "source": [
    "Skew Fixer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "157e56b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkewFixer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols =None, skew_threshold_left = -1, skew_threshold_right = 1):\n",
    "        self.cols = cols \n",
    "        self.skew_threshold_left = skew_threshold_left \n",
    "        self.skew_threshold_right = skew_threshold_right\n",
    "        self.skewed = []\n",
    "    def fit(self, X , y=None):\n",
    "        if self.cols is None :\n",
    "            self.cols = X.select_dtypes(include=[np.number]).columns\n",
    "        for col in self.cols:\n",
    "            sk = X[col].skew()\n",
    "            if sk > self.skew_threshold_right or sk < self.skew_threshold_left:\n",
    "                self.skewed.append(col)\n",
    "\n",
    "        return self ; \n",
    "\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        for col in self.skewed :\n",
    "            X_copy[col], _ = yeojohnson(X_copy[col])\n",
    "        return X_copy\n",
    "\n",
    "        \n",
    "    def fit_transform(self, X, y = None):\n",
    "        return self.transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e8ad1c",
   "metadata": {},
   "source": [
    "Company grouping :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97f7d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge sub-brands\n",
    "df['Company'] = df['Company'].replace({'Vero': 'Acer'})\n",
    "\n",
    "# Group companies with < 5 entries into 'Other'\n",
    "company_counts = df['Company'].value_counts()\n",
    "rare_companies = company_counts[company_counts < 5].index\n",
    "df['Company'] = df['Company'].replace(rare_companies, 'Other')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fdfabe",
   "metadata": {},
   "source": [
    "Scaling :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18b74859",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols ):\n",
    "        self.cols = cols\n",
    "        self.scalers={} \n",
    "    \n",
    "    def fit(self , X , y=None):\n",
    "        for col in self.cols :\n",
    "            stat , p = shapiro(X[col])\n",
    "            if p > 0.05:\n",
    "                scaler = StandardScaler()\n",
    "            else :\n",
    "                scaler = MinMaxScaler()\n",
    "            scaler.fit(X[[col]])  # <-- Ensure DataFrame input\n",
    "            self.scalers[col]=scaler \n",
    "        return self \n",
    "    \n",
    "    def transform(self , X , y=None):\n",
    "        X_copy = X.copy()\n",
    "        for col in self.cols :\n",
    "            X_copy[col]= self.scalers[col].transform(X_copy[[col]]).flatten()  # <-- Ensure DataFrame input\n",
    "        return X_copy\n",
    "    \n",
    "    def fit_transform(self, X, y = None):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf29f63",
   "metadata": {},
   "source": [
    "One hot Encoding the categorical columns :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fd2199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHot(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "        self.encoder = None \n",
    "        self.columnNames = None\n",
    "\n",
    "    def fit(self , X , y=None):\n",
    "        self.encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "        self.encoder.fit(X[self.cols])\n",
    "        self.column_names = self.encoder.get_feature_names_out(self.cols)\n",
    "        return self\n",
    "    \n",
    "    def transform(self , X , y=None):\n",
    "        X_copy = X.copy()\n",
    "        encoded = self.encoder.transform(X_copy[self.cols])\n",
    "        encodedDF = pd.DataFrame(encoded, columns=self.column_names, index=X_copy.index)\n",
    "        X_copy.drop(columns=self.cols, inplace=True)\n",
    "\n",
    "        X_copy= pd.concat([X_copy, encodedDF], axis=1)\n",
    "\n",
    "        return X_copy\n",
    "    \n",
    "    def fit_transform(self, X, y = None):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0312a8e0",
   "metadata": {},
   "source": [
    "Dropper :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "504561aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropColumnsTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols=None):\n",
    "        self.cols = cols\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.cols is None:\n",
    "            return X\n",
    "        else:\n",
    "            return X.drop(self.cols,axis=1)\n",
    "       \n",
    "    def fit_transform(self, X, y = None):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c722cef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Full_pipeline:\n",
    "    def __init__(self):\n",
    "        self.allcols= ['Company', 'TypeName', 'Inches', 'ScreenResolution', 'Cpu', 'Ram',\n",
    "                         'Memory', 'Gpu', 'OpSys', 'Weight']\n",
    "        \n",
    "        # Remove 'Gpu' from drop_cols to avoid KeyError\n",
    "        self.drop_cols = ['ScreenResolution', 'Cpu', 'Memory', 'OpSys', 'Inches']\n",
    "        \n",
    "        self.encode_cols = ['TypeName', 'Company', 'CPU type', 'Gpu', \"Operating System\"]\n",
    "        scaling_features = [\n",
    "            'Inches',\n",
    "            'Weight',\n",
    "            'Ram',\n",
    "            'PPI',\n",
    "            'HDD',\n",
    "            'SSD',\n",
    "            'Flash',\n",
    "            'CPU speed']\n",
    "        \n",
    "        self.full_pipeline= Pipeline([\n",
    "            ('Column selector', ColumnSelector(cols=self.allcols)),\n",
    "            (\"fix\", DataTypeFixer(cols=['Inches', 'Weight', 'Ram'])),\n",
    "            (\"Extract\", FeatureExtract(cols=['Gpu', 'Cpu', 'Memory', 'ScreenResolution','OpSys'])),\n",
    "            (\"fix skew\",SkewFixer(cols=['PPI', 'Weight', 'Ram','HDD', 'SSD',\"Flash\",'CPU speed' ])),\n",
    "            ('onehot', OneHot(cols=self.encode_cols)),\n",
    "            (\"scale\", Scaler(cols=scaling_features )),\n",
    "            ('dropper', DropColumnsTransformer(cols=self.drop_cols))\n",
    "        ])\n",
    "        \n",
    "        self.y_pipeline = Pipeline([\n",
    "            ('selector', ColumnSelector(cols=['Price'])),\n",
    "            ('power_transformation', SkewFixer(cols=['Price'])),\n",
    "            ('scaling', Scaler(cols=['Price']))\n",
    "        ])\n",
    "    \n",
    "    def fit_transform(self, X_train, y_train):\n",
    "        X_train = self.full_pipeline.fit_transform(X_train)\n",
    "        y_train = self.y_pipeline.fit_transform(y_train)\n",
    "        return X_train, y_train\n",
    "    \n",
    "    def transform(self, X_test, y_test):\n",
    "        X_test = self.full_pipeline.transform(X_test)\n",
    "        y_test = self.y_pipeline.transform(y_test)\n",
    "        return X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddede403",
   "metadata": {},
   "source": [
    "Now we split and preprocess the data !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b71dc756",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Price'])\n",
    "Y = df['Price']\n",
    "Y = pd.DataFrame(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c1d61c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           SSD   HDD    Flash\n",
      "950   0.007812  0.00  0.00000\n",
      "1121  0.250000  0.00  0.00000\n",
      "1292  0.000000  0.25  0.00000\n",
      "1247  0.250000  0.50  0.00000\n",
      "306   0.250000  0.00  0.00000\n",
      "838   0.000000  0.00  0.03125\n",
      "863   0.000000  0.50  0.00000\n",
      "1229  0.125000  0.50  0.00000\n",
      "1029  0.250000  0.00  0.00000\n",
      "361   0.250000  0.00  0.00000\n"
     ]
    }
   ],
   "source": [
    "# Show sample Memory values before feature extraction\n",
    "full_pipeline1 = Full_pipeline()\n",
    "X , Y = full_pipeline1.fit_transform(X, Y)\n",
    "X_train_pre, X_test_pre, y_train_pre, y_test_pre = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
    "# Show SSD, HDD, Flash after feature extraction\n",
    "print(X_train_pre[['SSD', 'HDD', 'Flash']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "877cb039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Ram       Weight    CPU speed          SSD          HDD  \\\n",
      "count  1082.000000  1082.000000  1082.000000  1082.000000  1082.000000   \n",
      "mean      0.119194     0.187233     0.518847     0.178424     0.205928   \n",
      "std       0.090614     0.073041     0.187059     0.183263     0.257735   \n",
      "min       0.000000     0.062145     0.000000     0.000000     0.000000   \n",
      "25%       0.047619     0.138723     0.407407     0.000000     0.000000   \n",
      "50%       0.111111     0.183769     0.592593     0.150391     0.000000   \n",
      "75%       0.111111     0.207869     0.666667     0.250000     0.500000   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "             Flash          IPS  Touchscreen          PPI  TypeName_Gaming  \\\n",
      "count  1082.000000  1082.000000  1082.000000  1082.000000      1082.000000   \n",
      "mean      0.009993     0.284658     0.144177     0.214327         0.160813   \n",
      "std       0.064361     0.451460     0.351432     0.165118         0.367529   \n",
      "min       0.000000     0.000000     0.000000     0.000000         0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.140339         0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.193326         0.000000   \n",
      "75%       0.000000     1.000000     0.000000     0.254951         0.000000   \n",
      "max       1.000000     1.000000     1.000000     1.000000         1.000000   \n",
      "\n",
      "       ...  Company_Toshiba  CPU type_Intel Core i3  CPU type_Intel Core i5  \\\n",
      "count  ...      1082.000000             1082.000000             1082.000000   \n",
      "mean   ...         0.036969                0.107209                0.317930   \n",
      "std    ...         0.188772                0.309522                0.465887   \n",
      "min    ...         0.000000                0.000000                0.000000   \n",
      "25%    ...         0.000000                0.000000                0.000000   \n",
      "50%    ...         0.000000                0.000000                0.000000   \n",
      "75%    ...         0.000000                0.000000                1.000000   \n",
      "max    ...         1.000000                1.000000                1.000000   \n",
      "\n",
      "       CPU type_Intel Core i7  CPU type_Other Intel Processor      Gpu_ARM  \\\n",
      "count             1082.000000                     1082.000000  1082.000000   \n",
      "mean                 0.407579                        0.118299     0.000924   \n",
      "std                  0.491611                        0.323112     0.030401   \n",
      "min                  0.000000                        0.000000     0.000000   \n",
      "25%                  0.000000                        0.000000     0.000000   \n",
      "50%                  0.000000                        0.000000     0.000000   \n",
      "75%                  1.000000                        0.000000     0.000000   \n",
      "max                  1.000000                        1.000000     1.000000   \n",
      "\n",
      "         Gpu_Intel   Gpu_Nvidia  Operating System_Others  \\\n",
      "count  1082.000000  1082.000000              1082.000000   \n",
      "mean      0.552680     0.304991                 0.116451   \n",
      "std       0.497447     0.460616                 0.320913   \n",
      "min       0.000000     0.000000                 0.000000   \n",
      "25%       0.000000     0.000000                 0.000000   \n",
      "50%       1.000000     0.000000                 0.000000   \n",
      "75%       1.000000     1.000000                 0.000000   \n",
      "max       1.000000     1.000000                 1.000000   \n",
      "\n",
      "       Operating System_Windows  \n",
      "count               1082.000000  \n",
      "mean                   0.866913  \n",
      "std                    0.339826  \n",
      "min                    0.000000  \n",
      "25%                    1.000000  \n",
      "50%                    1.000000  \n",
      "75%                    1.000000  \n",
      "max                    1.000000  \n",
      "\n",
      "[8 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pre.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b17e9b",
   "metadata": {},
   "source": [
    "Data is cleaned , Now Need to make the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6a45f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(random_state=ord(\"S\")),\n",
    "    Lasso(random_state=ord(\"S\")),\n",
    "    ElasticNet(random_state=ord(\"S\")),\n",
    "    DecisionTreeRegressor(random_state=ord(\"S\")),\n",
    "    RandomForestRegressor(random_state=ord(\"S\")),\n",
    "    GradientBoostingRegressor(random_state=ord(\"S\")),\n",
    "    XGBRegressor(random_state=ord(\"S\")),\n",
    "    ExtraTreesRegressor(random_state=ord(\"S\")),\n",
    "    BaggingRegressor(random_state=ord(\"S\")),\n",
    "    AdaBoostRegressor(random_state=ord(\"S\")),\n",
    "    CatBoostRegressor(random_state=ord(\"S\"),verbose=False),\n",
    "    SVR(),\n",
    "    KNeighborsRegressor()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "720d1152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, X_train, y_train, X_test, y_test, cv):\n",
    "    results = []\n",
    "\n",
    "    for model in models:\n",
    "        # Cross-validation scores\n",
    "        scores = cross_validate(model, X_train, y_train, cv=cv,scoring=['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2'],return_train_score=True)\n",
    "        \n",
    "        \n",
    "        mean_train_mae = -np.mean(scores['train_neg_mean_absolute_error'])\n",
    "        mean_train_rmse = np.sqrt(-np.mean(scores['train_neg_mean_squared_error']))\n",
    "        mean_train_r2 = np.mean(scores['train_r2'])\n",
    "        \n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        test_preds = model.predict(X_test)\n",
    "        \n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "        test_mae = mean_absolute_error(y_test, test_preds)\n",
    "        test_r2 = r2_score(y_test, test_preds)\n",
    "\n",
    "        \n",
    "        train_preds = model.predict(X_train)\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "        train_mae = mean_absolute_error(y_train, train_preds)\n",
    "        \n",
    "        # Store results\n",
    "        results_dict = {\n",
    "            'Algorithm': model.__class__.__name__,\n",
    "            'Train Score': mean_train_r2,\n",
    "            'Test Score': test_r2,\n",
    "            'Train MAE': mean_train_mae,\n",
    "            'Test MAE': test_mae,\n",
    "            'Train RMSE': train_rmse,\n",
    "            'Test RMSE': test_rmse,\n",
    "            'Train MSE': mean_train_rmse,\n",
    "            'Test MSE': test_rmse\n",
    "        }\n",
    "        results.append(results_dict)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.set_index('Algorithm', inplace=True)\n",
    "    results_df = results_df.sort_values(by='Test Score', ascending=False)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a80700f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_models(models , X_train_pre, y_train_pre, X_test_pre, y_test_pre,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3e182f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Train MAE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Train MSE</th>\n",
       "      <th>Test MSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CatBoostRegressor</th>\n",
       "      <td>0.971309</td>\n",
       "      <td>0.837766</td>\n",
       "      <td>0.014315</td>\n",
       "      <td>0.029394</td>\n",
       "      <td>0.020993</td>\n",
       "      <td>0.047281</td>\n",
       "      <td>0.020021</td>\n",
       "      <td>0.047281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.903179</td>\n",
       "      <td>0.825362</td>\n",
       "      <td>0.026795</td>\n",
       "      <td>0.031107</td>\n",
       "      <td>0.036807</td>\n",
       "      <td>0.049055</td>\n",
       "      <td>0.036772</td>\n",
       "      <td>0.049055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.997788</td>\n",
       "      <td>0.816366</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.029785</td>\n",
       "      <td>0.005855</td>\n",
       "      <td>0.050303</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.050303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.972976</td>\n",
       "      <td>0.804363</td>\n",
       "      <td>0.012371</td>\n",
       "      <td>0.031423</td>\n",
       "      <td>0.019111</td>\n",
       "      <td>0.051921</td>\n",
       "      <td>0.019421</td>\n",
       "      <td>0.051921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.993422</td>\n",
       "      <td>0.801536</td>\n",
       "      <td>0.005857</td>\n",
       "      <td>0.031143</td>\n",
       "      <td>0.011181</td>\n",
       "      <td>0.052295</td>\n",
       "      <td>0.009581</td>\n",
       "      <td>0.052295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor</th>\n",
       "      <td>0.967388</td>\n",
       "      <td>0.793936</td>\n",
       "      <td>0.013182</td>\n",
       "      <td>0.032344</td>\n",
       "      <td>0.021529</td>\n",
       "      <td>0.053287</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>0.053287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.764724</td>\n",
       "      <td>0.721478</td>\n",
       "      <td>0.040479</td>\n",
       "      <td>0.041091</td>\n",
       "      <td>0.057612</td>\n",
       "      <td>0.061951</td>\n",
       "      <td>0.057362</td>\n",
       "      <td>0.061951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.762552</td>\n",
       "      <td>0.721433</td>\n",
       "      <td>0.040588</td>\n",
       "      <td>0.040881</td>\n",
       "      <td>0.057811</td>\n",
       "      <td>0.061956</td>\n",
       "      <td>0.057626</td>\n",
       "      <td>0.061956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.997788</td>\n",
       "      <td>0.716423</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.039967</td>\n",
       "      <td>0.005855</td>\n",
       "      <td>0.062510</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.062510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.790483</td>\n",
       "      <td>0.695470</td>\n",
       "      <td>0.034350</td>\n",
       "      <td>0.041033</td>\n",
       "      <td>0.053557</td>\n",
       "      <td>0.064779</td>\n",
       "      <td>0.054121</td>\n",
       "      <td>0.064779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.702354</td>\n",
       "      <td>0.636939</td>\n",
       "      <td>0.056558</td>\n",
       "      <td>0.057752</td>\n",
       "      <td>0.063587</td>\n",
       "      <td>0.070730</td>\n",
       "      <td>0.064470</td>\n",
       "      <td>0.070730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.696530</td>\n",
       "      <td>0.615289</td>\n",
       "      <td>0.056533</td>\n",
       "      <td>0.059702</td>\n",
       "      <td>0.066915</td>\n",
       "      <td>0.072809</td>\n",
       "      <td>0.065192</td>\n",
       "      <td>0.072809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002739</td>\n",
       "      <td>0.089967</td>\n",
       "      <td>0.091888</td>\n",
       "      <td>0.118333</td>\n",
       "      <td>0.117547</td>\n",
       "      <td>0.118318</td>\n",
       "      <td>0.117547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002739</td>\n",
       "      <td>0.089967</td>\n",
       "      <td>0.091888</td>\n",
       "      <td>0.118333</td>\n",
       "      <td>0.117547</td>\n",
       "      <td>0.118318</td>\n",
       "      <td>0.117547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Train Score  Test Score  Train MAE  Test MAE  \\\n",
       "Algorithm                                                                 \n",
       "CatBoostRegressor             0.971309    0.837766   0.014315  0.029394   \n",
       "GradientBoostingRegressor     0.903179    0.825362   0.026795  0.031107   \n",
       "ExtraTreesRegressor           0.997788    0.816366   0.001020  0.029785   \n",
       "RandomForestRegressor         0.972976    0.804363   0.012371  0.031423   \n",
       "XGBRegressor                  0.993422    0.801536   0.005857  0.031143   \n",
       "BaggingRegressor              0.967388    0.793936   0.013182  0.032344   \n",
       "LinearRegression              0.764724    0.721478   0.040479  0.041091   \n",
       "Ridge                         0.762552    0.721433   0.040588  0.040881   \n",
       "DecisionTreeRegressor         0.997788    0.716423   0.001020  0.039967   \n",
       "KNeighborsRegressor           0.790483    0.695470   0.034350  0.041033   \n",
       "SVR                           0.702354    0.636939   0.056558  0.057752   \n",
       "AdaBoostRegressor             0.696530    0.615289   0.056533  0.059702   \n",
       "Lasso                         0.000000   -0.002739   0.089967  0.091888   \n",
       "ElasticNet                    0.000000   -0.002739   0.089967  0.091888   \n",
       "\n",
       "                           Train RMSE  Test RMSE  Train MSE  Test MSE  \n",
       "Algorithm                                                              \n",
       "CatBoostRegressor            0.020993   0.047281   0.020021  0.047281  \n",
       "GradientBoostingRegressor    0.036807   0.049055   0.036772  0.049055  \n",
       "ExtraTreesRegressor          0.005855   0.050303   0.005556  0.050303  \n",
       "RandomForestRegressor        0.019111   0.051921   0.019421  0.051921  \n",
       "XGBRegressor                 0.011181   0.052295   0.009581  0.052295  \n",
       "BaggingRegressor             0.021529   0.053287   0.021351  0.053287  \n",
       "LinearRegression             0.057612   0.061951   0.057362  0.061951  \n",
       "Ridge                        0.057811   0.061956   0.057626  0.061956  \n",
       "DecisionTreeRegressor        0.005855   0.062510   0.005556  0.062510  \n",
       "KNeighborsRegressor          0.053557   0.064779   0.054121  0.064779  \n",
       "SVR                          0.063587   0.070730   0.064470  0.070730  \n",
       "AdaBoostRegressor            0.066915   0.072809   0.065192  0.072809  \n",
       "Lasso                        0.118333   0.117547   0.118318  0.117547  \n",
       "ElasticNet                   0.118333   0.117547   0.118318  0.117547  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36d9cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
